# Introduce

안녕하세요, 저희는 한국의 네트워크챌린지 줄여서 넷챌린지 캠프 시즌10 경진대회에 참가했던 숭실대학교 DCN 연구실의 FedMec팀입니다.
이 넷챌린지는 다양한 네트워크 및 AI 등 기술들을 가지고 참가자들이 자신들의 아이디어를 펼치고 선보이는 대회입니다.
저희팀은 "분산 엣지 컴퓨팅 환경에서의 연합학습 머신러닝 서비스의 오케스트레이션 기능 개발"이란 주제로 참여하게 되었으며
6개월 간의 팀원과의 협업으로 대회에서 은상을 수상하는 영광을 갖게 되었습니다.

Hello. We are the project team "FedMec" of Soongsil Univ. DCN Lab that attended the south korea contest called NetChallenge season10.
Every Participant teams can show themselves idea in this NetChallenge contest.
Our team attended this contest with project "Orchestration feature of Federated Learning services in Distributed Edge Computing".
And we've glad to get the third winner title in this contest.

## Project Introduce(1)

분산학습이란 중앙서버에서 각 단말들로부터 데이터를 받아 학습을 진행하여 새로운 모델을 만들어내는 학습 방식을 의미한다.
하지만 이러한 분산학습에는 여러가지 문제점들이 있다.
1. 중앙서버에서 모든 데이터를 취합받고 있기에 서버에 대한 부하가 크다.(이로 인해 성능 저하의 이슈가 생길 수 있다)
2. 데이터의 직접 전달로 인해 데이터 보안의 위험성이 있다.

반면, 연합학습은 중앙집중식 학습 방식이 아닌 모델을 각 단말로 전달하여 각 단말에서 로컬 데이터를 가지고 모델을 학습하여 생성한 학습 파라미터들을 중앙서버에서 취합을 받아 새로운 모델을 만들어내는 학습 방식을 의미한다.
이러한 연합학습의 방식은 분산학습에서 단점이라고 꼽히는 부분들에 대한 커버가 가능하다.

하지만, 저희 연구팀은 연합학습을 공부하면서 연합학습 역시 단점들이 존재함을 발견할 수 있었다.
연합학습에서의 단점:
1. 일반적인 상황:
연합학습은 중앙서버에서 각 단말들로부터 학습이 완료된 학습 파라미터들을 취합한다고 이전에서 말했었는데 이때 각 단말마다의 스펙차이, 네트워크 환경의 차이 등등으로 인해 학습시간이 제각각일 경우가 있을 수 있다.
그러면 중앙서버에서 파라미터 취합을 진행할 때 어느 단말에서는 빨리 보내고 어느 단말에서는 느리게 보낸다면 중앙서버는 모든 파라미터들을 취합하려면 가장 느리게 학습시키고 파라미터를 올려보내는 단말이 완료될 때까지 대기해야 한다.
이는 전체 학습 시간에 영향을 미치는 이슈가 발생할 수 있다.
2. 학습시간을 줄이려는 상황:
만약에 연합학습의 학습 시간을 줄이려고 할 때 학습시간을 정해놓을 수 있겠죠. 그렇게되면 정해놓은 학습 시간 안에 도착한 학습 파라미터들은 취합되는데 문제없겠지만 학습이 늦어 정해진 학습 시간을 초과하여 보내오게 되면 그 학습 파라미터는 중앙서버에서 취합하지 않고 버리게 된다. 이때의 단점은 학습 결과의 편향성 이슈가 발생할 수 있다는 것이다.

Distributed learning refers to a learning method that receives data from each device on a centralized server and learns to create a new model.
However, there are several problems with distributed learning.
1. Since all data is collected from the central server, the load on the server is large (this can cause performance issues).
2. There is a risk of data security due to the direct transmission of data.

On the other hand, federated learning is not a centralized learning method, but a learning method that delivers the model to each terminal, and each terminal learns the model with local data, and the learning parameters generated by learning the model are collected from the central server to create a new model.
This method of federated learning can cover the shortcomings of distributed learning.

However, as our research team studied federated learning, we found that it also has its drawbacks.
Disadvantages of federated learning:
1. Common situation:
In the previous section, we mentioned that the central server collects the training parameters that have been trained from each terminal, but there may be cases where the training time is different due to the difference in the specification of each terminal, the difference in the network environment, etc.
Then, when the central server aggregates the parameters, if some devices send fast and some devices send slow, the central server must wait for the slowest device to finish learning and uploading parameters to aggregate all the parameters.
This can cause issues that affect the overall learning time.
2. You want to reduce the learning time:
If you want to reduce the learning time of federated learning, you can set a learning time. In that case, the learning parameters that arrive within the set learning time can be aggregated, but if the learning is late and the learning time exceeds the set learning time, the learning parameters will be discarded without being aggregated by the central server. The disadvantage of this is that it can cause bias in the learning results.

## Project Introduce(2)



## Bugs and Issues

Have a bug or an issue with this template? [Open a new issue](https://github.com/BlackrockDigital/startbootstrap-freelancer/issues) here on GitHub or leave a comment on the [template overview page at Start Bootstrap](http://startbootstrap.com/template-overviews/freelancer/).



## Creator

Start Bootstrap was created by and is maintained by **[David Miller](http://davidmiller.io/)**, Owner of [Blackrock Digital](http://blackrockdigital.io/).

* https://twitter.com/davidmillerskt
* https://github.com/davidtmiller

Start Bootstrap is based on the [Bootstrap](http://getbootstrap.com/) framework created by [Mark Otto](https://twitter.com/mdo) and [Jacob Thorton](https://twitter.com/fat).

## Copyright and License

Copyright 2013-2016 Blackrock Digital LLC. Code released under the [MIT](https://github.com/BlackrockDigital/startbootstrap-freelancer/blob/gh-pages/LICENSE) license.
